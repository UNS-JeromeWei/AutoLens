{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated lens design from scratch. This code uses classical RMS spot size for lens design, which is much faster than image-based lens design.\n",
    "\n",
    "Technical Paper:\n",
    "    Xinge Yang, Qiang Fu and Wolfgang Heidrich, \"Curriculum learning for ab initio deep learned refractive optics,\" ArXiv preprint 2023.\n",
    "\n",
    "This code and data is released under the Creative Commons Attribution-NonCommercial 4.0 International license (CC BY-NC.) In a nutshell:\n",
    "    # The license is only for non-commercial use (commercial licenses can be obtained from authors).\n",
    "    # The material is provided as-is, with no warranties whatsoever.\n",
    "    # If you publish any code, data, or scientific work based on this, please cite our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone 'https://github.com/singer-yang/AutoLens.git'\n",
    "!pip install transformers\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('./AutoLens'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import yaml\n",
    "import random\n",
    "import string\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from deeplens import GeoLens, DEPTH, WAVE_RGB, DEFAULT_WAVE, EPSILON, set_logger, set_seed, create_cellphone_lens, create_camera_lens, create_video_from_images\n",
    "\n",
    "def config():\n",
    "    \"\"\" Config file for training.\n",
    "    \"\"\"\n",
    "    # Config file\n",
    "    with open('configs/autolens.yml') as f:\n",
    "        args = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    # Result dir\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    random_string = ''.join(random.choice(characters) for i in range(4))\n",
    "    current_time = datetime.now().strftime(\"%m%d-%H%M%S\")\n",
    "    exp_name = current_time + '-AutoLens-RMS-' + random_string\n",
    "    result_dir = f'./results/{exp_name}'\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "    args['result_dir'] = result_dir\n",
    "    \n",
    "    if args['seed'] is None:\n",
    "        seed = random.randint(0, 100)\n",
    "        args['seed'] = seed\n",
    "    set_seed(args['seed'])\n",
    "    \n",
    "    # Log\n",
    "    set_logger(result_dir)\n",
    "    logging.info(f'EXP: {args[\"EXP_NAME\"]}')\n",
    "\n",
    "    # Device\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    args['num_gpus'] = num_gpus\n",
    "    device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    args['device'] = device\n",
    "    logging.info(f'Using {num_gpus} {torch.cuda.get_device_name(0)} GPU(s)')\n",
    "\n",
    "    return args\n",
    "\n",
    "def curriculum_design(self, lrs=[5e-4, 1e-4, 0.1, 1e-4], decay=0.02, iterations=5000, test_per_iter=100, importance_sampling=True, result_dir='./results'):\n",
    "        \"\"\" Optimize the lens by minimizing rms errors.\n",
    "        \"\"\"\n",
    "        # Preparation\n",
    "        depth = DEPTH\n",
    "        num_grid = 21\n",
    "        spp = 512\n",
    "        \n",
    "        centroid = False\n",
    "        sample_rays_per_iter = 5 * test_per_iter if centroid else test_per_iter\n",
    "        aper_start = self.surfaces[self.aper_idx].r * 0.5\n",
    "        aper_final = self.surfaces[self.aper_idx].r\n",
    "        \n",
    "        if not logging.getLogger().hasHandlers():\n",
    "            set_logger(result_dir)\n",
    "        logging.info(f'lr:{lrs}, decay:{decay}, iterations:{iterations}, spp:{spp}, grid:{num_grid}.')\n",
    "\n",
    "        optimizer = self.get_optimizer(lrs, decay)\n",
    "        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=iterations//10, num_training_steps=iterations)\n",
    "\n",
    "        # Training\n",
    "        pbar = tqdm(total=iterations+1, desc='Progress', postfix={'loss': 0})\n",
    "        for i in range(iterations+1):\n",
    "\n",
    "            # =====> Evaluate the lens\n",
    "            if i % test_per_iter == 0:\n",
    "                # Change aperture, curriculum learning\n",
    "                aper_r = min((aper_final - aper_start) * (i / iterations * 1.1) + aper_start, aper_final)\n",
    "                self.surfaces[self.aper_idx].r = aper_r\n",
    "                self.fnum = self.foclen / aper_r / 2\n",
    "                \n",
    "                # Correct shape and evaluate\n",
    "                if i > 0:   \n",
    "                    self.correct_shape()\n",
    "                self.write_lens_json(f'{result_dir}/iter{i}.json')\n",
    "                self.analysis(f'{result_dir}/iter{i}', zmx_format=True, plot_invalid=True, multi_plot=False)\n",
    "\n",
    "                    \n",
    "            # =====> Compute centriod and sample new rays\n",
    "            if i % sample_rays_per_iter == 0:\n",
    "                with torch.no_grad():\n",
    "                    # Sample rays\n",
    "                    scale = self.calc_scale_pinhole(depth)\n",
    "                    rays_backup = []\n",
    "                    for wv in WAVE_RGB:\n",
    "                        ray = self.sample_point_source(M=num_grid, R=self.sensor_size[0]/2*scale, depth=depth, spp=spp, pupil=True, wvln=wv, importance_sampling=importance_sampling)\n",
    "                        rays_backup.append(ray)\n",
    "\n",
    "                    # Calculate ray centers\n",
    "                    if centroid:\n",
    "                        center_p = - self.psf_center(point=ray.o[0, ...], method='chief_ray')\n",
    "                    else:\n",
    "                        center_p = - self.psf_center(point=ray.o[0, ...], method='pinhole')\n",
    "\n",
    "            # =====> Optimize lens by minimizing rms\n",
    "            loss_rms = []\n",
    "            for j, wv in enumerate(WAVE_RGB):\n",
    "                # Ray tracing\n",
    "                ray = rays_backup[j].clone()\n",
    "                ray, _, _ = self.trace(ray)\n",
    "                xy = ray.project_to(self.d_sensor)\n",
    "                xy_norm = (xy - center_p) * ray.ra.unsqueeze(-1)\n",
    "\n",
    "                # Weighted loss\n",
    "                weight_mask = (xy_norm.clone().detach()**2).sum([0, -1]) / (ray.ra.sum([0]) + EPSILON) # Use L2 error as weight mask\n",
    "                weight_mask /= weight_mask.mean()   # shape of [M, M]\n",
    "                \n",
    "                l_rms = torch.sqrt(torch.sum((xy_norm**2 + EPSILON).sum(-1) * weight_mask) / (torch.sum(ray.ra) + EPSILON))  # weighted L2 loss\n",
    "                loss_rms.append(l_rms)\n",
    "\n",
    "            loss_rms = sum(loss_rms) / len(loss_rms)\n",
    "\n",
    "            # Regularization\n",
    "            loss_reg = self.loss_reg()\n",
    "            w_reg = 0.1\n",
    "            L_total = loss_rms + w_reg * loss_reg\n",
    "\n",
    "            # Gradient-based optimization\n",
    "            optimizer.zero_grad()\n",
    "            L_total.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            pbar.set_postfix(rms=loss_rms.item())\n",
    "            pbar.update(1)\n",
    "\n",
    "        pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    args = config()\n",
    "    result_dir = args['result_dir']\n",
    "    device = args['device']\n",
    "\n",
    "    # Bind function\n",
    "    GeoLens.curriculum_design = curriculum_design\n",
    "\n",
    "    # ===> Create a cellphone lens\n",
    "    lens = create_cellphone_lens(hfov=args['HFOV'], imgh=args['DIAG'], fnum=args['FNUM'], lens_num=args['lens_num'], save_dir=result_dir)\n",
    "    lens.set_target_fov_fnum(hfov=args['HFOV'], fnum=args['FNUM'], imgh=args['DIAG'])\n",
    "    logging.info(f'==> Design target: FOV {round(args[\"HFOV\"]*2*57.3, 2)}, DIAG {args[\"DIAG\"]}mm, F/{args[\"FNUM\"]}, FOCLEN {round(args[\"DIAG\"]/2/np.tan(args[\"HFOV\"]), 2)}mm.')\n",
    "    \n",
    "    # # ===> Create a camera lens\n",
    "    # lens = create_camera_lens(foclen=args['FOCLEN'], imgh=args['DIAG'], fnum=args['FNUM'], lens_num=args['lens_num'], save_dir=result_dir)\n",
    "    # lens.set_target_fov_fnum(hfov=float(np.arctan(args['DIAG'] / args['FOCLEN'] / 2)), fnum=args['FNUM'], imgh=args['DIAG'])\n",
    "    # logging.info(f'==> Design target: FOCLEN {round(args[\"FOCLEN\"], 2)}, DIAG {args[\"DIAG\"]}mm, F/{args[\"FNUM\"]}')\n",
    "    \n",
    "    # =====> 2. Curriculum learning with RMS errors\n",
    "    lrs = [float(lr) for lr in args['lrs']]\n",
    "    lens.curriculum_design(lrs=lrs, decay=0.01, iterations=5000, test_per_iter=50, result_dir=args['result_dir'])\n",
    "\n",
    "    # Need to train more for the best optical performance\n",
    "\n",
    "    # =====> 3. Analyze final result\n",
    "    lens.prune_surf(outer=0.05)\n",
    "    lens.post_computation()\n",
    "\n",
    "    logging.info(f'Actual: FOV {lens.hfov}, IMGH {lens.r_last}, F/{lens.fnum}.')\n",
    "    lens.write_lens_json(f'{result_dir}/final_lens.json')\n",
    "    lens.analysis(save_name=f'{result_dir}/final_lens', zmx_format=True)\n",
    "\n",
    "    # =====> 4. Create video\n",
    "    create_video_from_images(f'{result_dir}', f'{result_dir}/autolens.mp4', fps=10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
